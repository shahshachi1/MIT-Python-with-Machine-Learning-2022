{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Data-Science-and-Data-Analytics-Courses/MITx---Machine-Learning-with-Python-From-Linear-Models-to-Deep-Learning-Jun-11-2019/blob/master/homeworks/Homework2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6tGpYtc6asY",
        "colab_type": "text"
      },
      "source": [
        "# Packages and libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAQaKOFS6pMs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from itertools import chain\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8DoUAdW4prA",
        "colab_type": "text"
      },
      "source": [
        "# 3. Perceptron Updates\n",
        "In this problem, we will try to understand the convergence of perceptron algorithm and its relation to the ordering of the training samples for the following simple example.\n",
        "\n",
        "Consider a set of  n=d  labeled  d− dimensional feature vectors,  {(x(t),y(t)),t=1,…,d}  defined as follows:\n",
        "\n",
        " \t x(t)i \t = \t cos(πt)ifi=t \t \t(3.7)\n",
        " \t x(t)i \t = \t 0otherwise, \t \t(3.8)\n",
        "Recall the no-offset perceptron algorithm, and assume that  θ⋅x=0  is treated as a mistake, regardless of label. Assume that in all of the following problems, we initialize  θ=0  and when we refer to the perceptron algorithm we only consider the no-offset variant of it.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cXl8yXgU6no",
        "colab_type": "text"
      },
      "source": [
        "### Working out Perceptron Algorithm\n",
        "3 points possible (graded)  \n",
        "Consider the d=2 case. Let y(1)=1,y(2)=1. Assume that the feature vector x(1) is presented to the perceptron algorithm before x(2).\n",
        "\n",
        "For this particular assignment of labels, work out the perceptron algorithm until convergence.\n",
        "\n",
        "Let θ^ be the resulting θ value after convergence. Note that for d=2, θ^ would be a two-dimensional vector. Let's denote the first and second components of θ^ by θ^1 and θ^2 respectively.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "93424fa7-3cfc-4e87-b860-edf5dfc82909",
        "id": "9-P2BWV7VSvX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def perceptron(x, y, w=None, fixed_offset=False, iters=1000):\n",
        "  \"\"\"\n",
        "  Decision boundary: wx(i) = 0 (including offset)\n",
        "  w: if None, initialize to 0\n",
        "  fixed_offset: if True, not update offset\n",
        "  \"\"\"\n",
        "  \n",
        "  n, d = x.shape\n",
        "  x = np.column_stack((np.ones(n), x)) # add preceding 1's\n",
        "  if w is None:\n",
        "    w = np.zeros(d + 1) # add preceding offset\n",
        "  else:\n",
        "    w = np.array(w, dtype=float)\n",
        "\n",
        "  weights = [] # intermediate weights\n",
        "  for k in range(iters):\n",
        "    converged = True\n",
        "    for i in range(n):\n",
        "      if y[i] * w.dot(x[i]) <= 0: # misclassified\n",
        "        # Update weight\n",
        "        if fixed_offset: # not update offset\n",
        "          w[1:] += y[i]*x[i][1:]\n",
        "        else:\n",
        "          w += y[i]*x[i]\n",
        "        weights.append(w.tolist()) # capture intermediate weight\n",
        "        converged = False\n",
        "    \n",
        "    if converged:\n",
        "      break\n",
        "  \n",
        "  return weights\n",
        "\n",
        "x = np.array([[np.cos(np.pi), 0], [0, np.cos(2*np.pi)]])\n",
        "y = np.array([1, 1])\n",
        "weights = perceptron(x, y, fixed_offset=True)\n",
        "print(weights)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.0, -1.0, 0.0], [0.0, -1.0, 1.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}