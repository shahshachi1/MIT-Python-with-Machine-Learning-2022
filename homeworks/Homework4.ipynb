{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Data-Science-and-Data-Analytics-Courses/MITx---Machine-Learning-with-Python-From-Linear-Models-to-Deep-Learning-Jun-11-2019/blob/master/homeworks/Homework4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jKf749g6256",
        "colab_type": "text"
      },
      "source": [
        "# Homework 4\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiqX2dH_HnE0",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Xw3SOTRf9Nz_",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "\n",
        "# Notebook Library\n",
        "url = \"https://github.com/Data-Science-and-Data-Analytics-Courses/Notebook-Library\"\n",
        "repo = Path(\"/nblib\")\n",
        "!git clone \"{url}\" \"{repo}\"\n",
        "if repo.parent.as_posix() not in sys.path:\n",
        "  sys.path.append(repo.parent.as_posix())\n",
        "%run \"{repo}/.Importable.ipynb\"\n",
        "\n",
        "from nblib.imports.Basic import *\n",
        "from nblib import Git\n",
        "\n",
        "# Remote\n",
        "URL = \"https://github.com/Data-Science-and-Data-Analytics-Courses/MITx---Machine-Learning-with-Python-From-Linear-Models-to-Deep-Learning-Jun-11-2019\"\n",
        "REPO = Git.clone(URL, dest=\"/content\")\n",
        "if REPO.as_posix() not in sys.path:\n",
        "  sys.path.append(REPO.as_posix())\n",
        "\n",
        "# Working directory\n",
        "os.chdir(REPO)\n",
        "\n",
        "from nblib.imports.DS import *\n",
        "from setup.Setup import *\n",
        "from nblib import File\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_G3NIBvQB-yv",
        "colab_type": "text"
      },
      "source": [
        "##  Neural Networks\n",
        "In this problem we will analyze a simple neural network to understand its classification properties. Consider the neural network given in the figure below, with ReLU activation functions (denoted by  f ) on all neurons, and a softmax activation function in the output layer:  \n",
        "Given an input  x=[x1,x2]T , the hidden units in the network are activated in stages as described by the following equations:  \n",
        "z1 \t=x1W11+x2W21+W01\tf(z1)\t=max{z1,0}\t \t \n",
        " \tz2\t=x1W12+x2W22+W02\tf(z2)\t=max{z2,0}\t \t \n",
        " \tz3\t=x1W13+x2W23+W03\tf(z3)\t=max{z3,0}\t \t \n",
        " \tz4\t=x1W14+x2W24+W04\tf(z4)\t=max{z4,0}\t \n",
        "u1 \t=f(z1)V11+f(z2)V21+f(z3)V31+f(z4)V41+V01\tf(u1)\t=max{u1,0}\t \t \n",
        " \tu2\t=f(z1)V12+f(z2)V22+f(z3)V32+f(z4)V42+V02\tf(u2)\t=max{u2,0}.\t \n",
        "The final output of the network is obtained by applying the softmax function to the last hidden layer,\n",
        "\n",
        "$$\n",
        "o1 \\displaystyle = \\frac{e^{f(u_1)}}{e^{f(u_1)} +e^{f(u_2)}} \\\\\n",
        "o2 \\displaystyle = \\frac{e^{f(u_1)}}{e^{f(u_1)} +e^{f(u_2)}}\n",
        "$$o2 \t =ef(u2)ef(u1)+ef(u2). \t \n",
        "In this problem, we will consider the following setting of parameters:  \n",
        "$$\n",
        "\\left[ \\begin{array}{ccc} W_{11} &  W_{21} &  W_{01} \\\\ W_{12} &  W_{22} &  W_{02} \\\\ W_{13} &  W_{23} &  W_{03} \\\\ W_{14} &  W_{24} &  W_{04} \\\\ \\end{array}\\right] = \\left[\\begin{array}{ccc} 1 &  0 &  -1 \\\\ 0 &  1 &  -1 \\\\ -1 &  0 &  -1 \\\\ 0 &  -1 &  -1 \\end{array}\\right],\n",
        "$$\n",
        "$$\n",
        "\\left[ \\begin{array}{ccccc} V_{11} &  V_{21} &  V_{31} &  V_{41} &  V_{01} \\\\ V_{12} &  V_{22} &  V_{32} &  V_{42} &  V_{02} \\end{array} \\right] = \\left[ \\begin{array}{ccccc} 1 &  1 &  1 &  1 &  0 \\\\ -1 &  -1 &  -1 &  -1&  2 \\end{array}\\right].\n",
        "$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93XGwmp0qT_i",
        "colab_type": "text"
      },
      "source": [
        "### Feed Forward Step\n",
        "Consider the input  x1=3 ,  x2=14 . What is the final output  (o1,o2)  of the network?\n",
        "\n",
        "Important: Numerical outputs from the softmax function are sometimes extremely close to 0 or 1; if you choose to enter your answers numerically, make sure to report them to at least 9 decimal places! (Alternatively, you may enter your answers symbolically as a function of symbolically  e .)  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWRly0_pqUyO",
        "colab_type": "code",
        "outputId": "53e8d41d-54b9-4bea-dece-411090c384c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "w = np.array([[1, 0, -1], \n",
        "              [0, 1, -1],\n",
        "              [-1, 0, -1],\n",
        "              [0, -1, -1]])\n",
        "v = np.array([[1, 1, 1, 1, 0],\n",
        "              [-1, -1, -1, -1, 2]])\n",
        "\n",
        "x = np.array([[3, 14, 1]])\n",
        "z =  x.dot(w.T)\n",
        "fz = np.maximum(z, 0)\n",
        "fz = np.insert(fz, fz.shape[1], 1, axis=1) # add 1-column to the end\n",
        "u = np.maximum(fz.dot(v.T), 0)\n",
        "o = spec.softmax(u, axis=1)\n",
        "o"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.99999694e-01, 3.05902227e-07]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anfl4nweLN8G",
        "colab_type": "text"
      },
      "source": [
        "## LSTM\n",
        "The diagram below shows a single LSTM unit that consists of Input, Output, and Forget gates.  \n",
        "![alt text](https://prod-edxapp.edx-cdn.org/assets/courseware/v1/8e7c0fe7c60323338b556ae490d116cf/asset-v1:MITx+6.86x+1T2019+type@asset+block/images_hw4_p2.png)\n",
        "The behavior of such a unit as a recurrent neural network is specified by a set of update equations. These equations define how the gates, “memory cell\"  ct  and the “visible state\"  ht  are updated in response to input  xt  and previous states  ct−1 ,  ht−1 . For the LSTM unit,  \n",
        "\n",
        "$$\n",
        "ft \t\\displaystyle = \\text {sigmoid}(W^{f,h} h_{t-1} + W^{f,x} x_ t + b_ f ) \\\\\n",
        " \tit\t\\displaystyle = \\text {sigmoid}(W^{i,h} h_{t-1} + W^{i,x} x_ t + b_ i ) \\\\\n",
        " \tot\t\\displaystyle = \\text {sigmoid}(W^{o,h} h_{t-1} + W^{o,x} x_ t + b_ o ) \\\\\n",
        " \tct\t\\displaystyle = f_ t \\odot c_{t-1} + i_ t \\odot \\tanh (W^{c,h} h_{t-1} + W^{c,x} x_ t + b_ c) \\\\\n",
        " \tht\t\\displaystyle = o_ t \\odot \\tanh (c_ t) \\\\\n",
        "$$\n",
        "\n",
        "where symbol  ⊙  stands for element-wise multiplication. The adjustable parameters in this unit are matrices  Wf,h ,  Wf,x ,  Wi,h ,  Wi,x ,  Wo,h ,  Wo,x ,  Wc,h ,  Wc,x , as well as the offset parameter vectors  bf ,  bi ,  bo , and  bc . By changing these parameters, we change how the unit evolves as a function of inputs  xt .\n",
        "\n",
        "To keep things simple, in this problem we assume that  xt ,  ct , and  ht  are all scalars. Concretely, suppose that the parameters are given by\n",
        "\n",
        " \t Wf,h \t =0 \t Wf,x \t =0 \t bf \t =−100 \t Wc,h \t =−100 \t \t \n",
        " \t Wi,h \t =0 \t Wi,x \t =100 \t bi \t =100 \t Wc,x \t =50 \t \t \n",
        " \t Wo,h \t =0 \t Wo,x \t =100 \t bo \t =0, \t bc \t =0 \t \t \n",
        "We run this unit with initial conditions  h−1=0  and  c−1=0 , and in response to the following input sequence: [0, 0, 1, 1, 1, 0] (For example,  x0=0 ,  x1=0 ,  x2=1 , and so on).  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Msn_cj3_LrjS",
        "colab_type": "text"
      },
      "source": [
        "### LSTM states\n",
        "Calculate the values  ht  at each time-step and enter them below as an array  [h0,h1,h2,h3,h4,h5] . For ease of calculation, you can assume that you round  ht  to the closest integer in every time-step. E.g., assume  sigmoid(50)≈1  and  tanh(−50)≈−1 .  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdvNWtJd5ExB",
        "colab_type": "code",
        "outputId": "5d72958e-f785-4ace-8e0d-0dcc5edba16e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "W_fh = 0; W_fx = 0; bf = -100         \n",
        "W_ih = 0; W_ix = 100; bi = 100              \n",
        "W_oh = 0; W_ox = 100; bo = 0    \n",
        "W_ch = -100; W_cx = 50; bc = 0\n",
        "\n",
        "h0 = 0; c0 = 0 # initial states\n",
        "x = np.array([0, 0, 1, 1, 1, 0])\n",
        "Wh = np.stack((W_fh, W_ih, W_oh, W_ch), axis=0)\n",
        "Wx = np.stack((W_fx, W_ix, W_ox, W_cx), axis=0)\n",
        "b = np.stack((bf, bi, bo, bc), axis=0)\n",
        "\n",
        "states = np.zeros((len(x)+1, 2))\n",
        "states[0] = [h0, c0] # current states\n",
        "for (j,), val in np.ndenumerate(x):\n",
        "  h, c = states[j] # current states\n",
        "  zf, zi, zo, zc = h*Wh + val*Wx + b # linear transformations\n",
        "  f, i, o = map(spec.expit, [zf, zi, zo])\n",
        "\n",
        "  # New states\n",
        "  c = f * c + i * np.tanh(zc)\n",
        "  h = np.rint(o * np.tanh(c))\n",
        "  states[j+1] = [h, c]\n",
        "h_updates = states[1:, 0]\n",
        "print(h_updates)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.  0.  1. -1.  1. -0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ErpkAOknhjH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "817d9ec4-0dac-471d-8de7-22c65bc5f87b"
      },
      "source": [
        "spec.expit(100)\n",
        "np.tanh(1)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7615941559557649"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    }
  ]
}