{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project1_Algorithms.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Data-Science-and-Data-Analytics-Courses/MITx---Machine-Learning-with-Python-From-Linear-Models-to-Deep-Learning-Jun-11-2019/blob/master/Unit%201%20Linear%20Classifiers%20and%20Generalizations%20(2%20weeks)/Project%201%3A%20Automatic%20Review%20Analyzer/Project1_Algorithms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WI45ce2OcpDu",
        "colab_type": "text"
      },
      "source": [
        "# Project 1: Algorithms\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "duYMp7B1shFR",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import numpy.testing as npt\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5sl8tFrDP67Z"
      },
      "source": [
        "## Hinge Loss\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqyzKOPt2NXR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_order(n_samples):\n",
        "    try:\n",
        "        with open(\"sentiment_analysis/\" + str(n_samples) + '.txt') as fp:\n",
        "            line = fp.readline()\n",
        "            return list(map(int, line.split(',')))\n",
        "    except FileNotFoundError:\n",
        "        random.seed(1)\n",
        "        indices = list(range(n_samples))\n",
        "        random.shuffle(indices)\n",
        "        return indices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTwFNVtH71cP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def hinge_loss_single(feature_vector, label, theta, theta_0):\n",
        "    \"\"\"\n",
        "    Finds the hinge loss on a single data point given specific classification\n",
        "    parameters.\n",
        "\n",
        "    Args:\n",
        "        feature_vector - A numpy array describing the given data point.\n",
        "        label - A real valued number, the correct classification of the data\n",
        "            point.\n",
        "        theta - A numpy array describing the linear classifier.\n",
        "        theta_0 - A real valued number representing the offset parameter.\n",
        "\n",
        "\n",
        "    Returns: A real number representing the hinge loss associated with the\n",
        "    given data point and parameters.\n",
        "    \"\"\"\n",
        "    # Your code here\n",
        "    pred = np.dot(theta, feature_vector) + theta_0\n",
        "    loss = max(0, 1-label*pred)\n",
        "    \n",
        "    return loss\n",
        "  \n",
        "if __name__ == \"__main__\":\n",
        "  feature_vector = np.array([1, 2])\n",
        "  label, theta, theta_0 = 1, np.array([-1, 1]), -0.2\n",
        "  exp_res = 1 - 0.8\n",
        "  assert exp_res == hinge_loss_single(feature_vector, label, theta, theta_0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMCa4w4W-O0n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def hinge_loss_full(feature_matrix, labels, theta, theta_0):\n",
        "    \"\"\"\n",
        "    Finds the total hinge loss on a set of data given specific classification\n",
        "    parameters.\n",
        "\n",
        "    Args:\n",
        "        feature_matrix - A numpy matrix describing the given data. Each row\n",
        "            represents a single data point.\n",
        "        labels - A numpy array where the kth element of the array is the\n",
        "            correct classification of the kth row of the feature matrix.\n",
        "        theta - A numpy array describing the linear classifier.\n",
        "        theta_0 - A real valued number representing the offset parameter.\n",
        "\n",
        "\n",
        "    Returns: A real number representing the hinge loss associated with the\n",
        "    given dataset and parameters. This number should be the average hinge\n",
        "    loss across all of the points in the feature matrix.\n",
        "    \"\"\"\n",
        "    # Your code here\n",
        "    predictions = np.dot(feature_matrix, theta) + theta_0\n",
        "    losses = np.maximum(np.zeros(len(predictions)), 1 - labels * predictions)\n",
        "    loss = np.mean(losses)\n",
        "    \n",
        "    return loss\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  feature_matrix = np.array([[1, 2], [1, 2]])\n",
        "  labels, theta, theta_0 = np.array([1, 1]), np.array([-1, 1]), -0.2\n",
        "  exp_res = 1 - 0.8\n",
        "  assert exp_res == hinge_loss_full(feature_matrix, labels, theta, theta_0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsKVVNGZnERg",
        "colab_type": "text"
      },
      "source": [
        "## Perceptron Algorithm\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiYN3HyYnJ8d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def perceptron_single_step_update(\n",
        "        feature_vector,\n",
        "        label,\n",
        "        current_theta,\n",
        "        current_theta_0):\n",
        "    \"\"\"\n",
        "    Properly updates the classification parameter, theta and theta_0, on a\n",
        "    single step of the perceptron algorithm.\n",
        "\n",
        "    Args:\n",
        "        feature_vector - A numpy array describing a single data point.\n",
        "        label - The correct classification of the feature vector.\n",
        "        current_theta - The current theta being used by the perceptron\n",
        "            algorithm before this update.\n",
        "        current_theta_0 - The current theta_0 being used by the perceptron\n",
        "            algorithm before this update.\n",
        "\n",
        "    Returns: A tuple where the first element is a numpy array with the value of\n",
        "    theta after the current update has completed and the second element is a\n",
        "    real valued number with the value of theta_0 after the current updated has\n",
        "    completed.\n",
        "    \"\"\"\n",
        "    # Your code here\n",
        "    theta = np.array(current_theta)\n",
        "    theta_0 = current_theta_0\n",
        "    if label * (theta.dot(feature_vector) + theta_0) <= 0: # misclassified\n",
        "      theta += label * feature_vector # update theta\n",
        "      theta_0 += label # update theta 0\n",
        "    \n",
        "    return theta, theta_0\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "  feature_vector = np.array([1, 2])\n",
        "  label, theta, theta_0 = 1, np.array([-1, 1]), -1.5\n",
        "  exp_theta, exp_theta_0 = (np.array([0, 3]), -0.5)\n",
        "  upd_theta, upd_theta_0 = perceptron_single_step_update(feature_vector, label, theta, theta_0)\n",
        "  assert np.all(upd_theta == exp_theta)\n",
        "  assert upd_theta_0 == exp_theta_0\n",
        "\n",
        "  feature_vector = np.array([1, 2])\n",
        "  label, theta, theta_0 = 1, np.array([-1, 1]), -1\n",
        "  exp_theta, exp_theta_0 = (np.array([0, 3]), 0)\n",
        "  upd_theta, upd_theta_0 = perceptron_single_step_update(feature_vector, label, theta, theta_0)\n",
        "  assert np.all(upd_theta == exp_theta)\n",
        "  assert upd_theta_0 == exp_theta_0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k50IeQxCw9uc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def perceptron(feature_matrix, labels, T):\n",
        "    \"\"\"\n",
        "    Runs the full perceptron algorithm on a given set of data. Runs T\n",
        "    iterations through the data set, there is no need to worry about\n",
        "    stopping early.\n",
        "\n",
        "    NOTE: Please use the previously implemented functions when applicable.\n",
        "    Do not copy paste code from previous parts.\n",
        "\n",
        "    NOTE: Iterate the data matrix by the orders returned by get_order(feature_matrix.shape[0])\n",
        "\n",
        "    Args:\n",
        "        feature_matrix -  A numpy matrix describing the given data. Each row\n",
        "            represents a single data point.\n",
        "        labels - A numpy array where the kth element of the array is the\n",
        "            correct classification of the kth row of the feature matrix.\n",
        "        T - An integer indicating how many times the perceptron algorithm\n",
        "            should iterate through the feature matrix.\n",
        "\n",
        "    Returns: A tuple where the first element is a numpy array with the value of\n",
        "    theta, the linear classification parameter, after T iterations through the\n",
        "    feature matrix and the second element is a real number with the value of\n",
        "    theta_0, the offset classification parameter, after T iterations through\n",
        "    the feature matrix.\n",
        "    \"\"\"\n",
        "    # Your code here\n",
        "    theta, theta_0 = np.zeros(feature_matrix.shape[1]), 0\n",
        "    for t in range(T):\n",
        "        for i in get_order(feature_matrix.shape[0]):\n",
        "            # Your code here\n",
        "            if labels[i] * (theta.dot(feature_matrix[i]) + theta_0) <= 0: # misclassified\n",
        "              theta += labels[i] * feature_matrix[i] # update theta\n",
        "              theta_0 += labels[i] # update theta 0\n",
        "              \n",
        "    return theta, theta_0\n",
        "\n",
        "def test_perceptron(feature_matrix, labels, T, exp_theta, exp_theta_0):\n",
        "  theta, theta_0 = perceptron(feature_matrix, labels, T)\n",
        "  assert np.all(theta == exp_theta)\n",
        "  assert theta_0 == exp_theta_0\n",
        "  \n",
        "if __name__ == \"__main__\":\n",
        "  feature_matrix = np.array([[1, 2]])\n",
        "  labels = np.array([1])\n",
        "  T = 1\n",
        "  exp_theta, exp_theta_0 = (np.array([1, 2]), 1)\n",
        "  test_perceptron(feature_matrix, labels, T, exp_theta, exp_theta_0)\n",
        "\n",
        "  feature_matrix = np.array([[1, 2], [-1, 0]])\n",
        "  labels = np.array([1, 1])\n",
        "  T = 1\n",
        "  exp_theta, exp_theta_0 = (np.array([0, 2]), 2)\n",
        "  test_perceptron(feature_matrix, labels, T, exp_theta, exp_theta_0)\n",
        "\n",
        "  feature_matrix = np.array([[1, 2]])\n",
        "  labels = np.array([1])\n",
        "  T = 2\n",
        "  exp_theta, exp_theta_0 = (np.array([1, 2]), 1)\n",
        "  test_perceptron(feature_matrix, labels, T, exp_theta, exp_theta_0)\n",
        "\n",
        "  feature_matrix = np.array([[1, 2], [-1, 0]])\n",
        "  labels = np.array([1, 1])\n",
        "  T = 2\n",
        "  exp_theta, exp_theta_0 = (np.array([0, 2]), 2)\n",
        "  test_perceptron(feature_matrix, labels, T, exp_theta, exp_theta_0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCVz2VmrWLSg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def average_perceptron(feature_matrix, labels, T):\n",
        "    \"\"\"\n",
        "    Runs the average perceptron algorithm on a given set of data. Runs T\n",
        "    iterations through the data set, there is no need to worry about\n",
        "    stopping early.\n",
        "\n",
        "    NOTE: Please use the previously implemented functions when applicable.\n",
        "    Do not copy paste code from previous parts.\n",
        "\n",
        "    NOTE: Iterate the data matrix by the orders returned by get_order(feature_matrix.shape[0])\n",
        "\n",
        "\n",
        "    Args:\n",
        "        feature_matrix -  A numpy matrix describing the given data. Each row\n",
        "            represents a single data point.\n",
        "        labels - A numpy array where the kth element of the array is the\n",
        "            correct classification of the kth row of the feature matrix.\n",
        "        T - An integer indicating how many times the perceptron algorithm\n",
        "            should iterate through the feature matrix.\n",
        "\n",
        "    Returns: A tuple where the first element is a numpy array with the value of\n",
        "    the average theta, the linear classification parameter, found after T\n",
        "    iterations through the feature matrix and the second element is a real\n",
        "    number with the value of the average theta_0, the offset classification\n",
        "    parameter, found after T iterations through the feature matrix.\n",
        "\n",
        "    Hint: It is difficult to keep a running average; however, it is simple to\n",
        "    find a sum and divide.\n",
        "    \"\"\"\n",
        "    # Your code here\n",
        "    theta, theta_0 = np.zeros(feature_matrix.shape[1]), 0\n",
        "    theta_sum, theta_0_sum = np.zeros(feature_matrix.shape[1]), 0\n",
        "    for t in range(T):\n",
        "        for i in get_order(feature_matrix.shape[0]):\n",
        "            # Your code here\n",
        "            if labels[i] * (theta.dot(feature_matrix[i]) + theta_0) <= 0: # misclassified\n",
        "              theta += labels[i] * feature_matrix[i] # update theta\n",
        "              theta_0 += labels[i] # update theta 0\n",
        "            theta_sum += theta\n",
        "            theta_0_sum += theta_0\n",
        "    \n",
        "    theta_avg = theta_sum / (feature_matrix.shape[0] * T)\n",
        "    theta_0_avg = theta_0_sum / (feature_matrix.shape[0] * T)\n",
        "              \n",
        "    return theta_avg, theta_0_avg\n",
        "\n",
        "def test_average_perceptron(feature_matrix, labels, T, exp_theta, exp_theta_0):\n",
        "  theta_avg, theta_0_avg = average_perceptron(feature_matrix, labels, T)\n",
        "  assert np.all(theta_avg == exp_theta)\n",
        "  assert theta_0_avg == exp_theta_0\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  feature_matrix = np.array([[1, 2]])\n",
        "  labels = np.array([1])\n",
        "  T = 1\n",
        "  exp_theta, exp_theta_0 = (np.array([1, 2]), 1)\n",
        "  test_average_perceptron(feature_matrix, labels, T, exp_theta, exp_theta_0)\n",
        "\n",
        "  feature_matrix = np.array([[1, 2], [-1, 0]])\n",
        "  labels = np.array([1, 1])\n",
        "  T = 1\n",
        "  exp_theta, exp_theta_0 = (np.array([-0.5, 1]), 1.5)\n",
        "  test_average_perceptron(feature_matrix, labels, T, exp_theta, exp_theta_0)\n",
        "\n",
        "  feature_matrix = np.array([[1, 2]])\n",
        "  labels = np.array([1])\n",
        "  T = 2\n",
        "  exp_theta, exp_theta_0 = (np.array([1, 2]), 1)\n",
        "  test_average_perceptron(feature_matrix, labels, T, exp_theta, exp_theta_0)\n",
        "\n",
        "  feature_matrix = np.array([[1, 2], [-1, 0]])\n",
        "  labels = np.array([1, 1])\n",
        "  T = 2\n",
        "  exp_theta, exp_theta_0 = (np.array([-0.25, 1.5]), 1.75)\n",
        "  test_average_perceptron(feature_matrix, labels, T, exp_theta, exp_theta_0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RpviN1ucSPg",
        "colab_type": "text"
      },
      "source": [
        "## Pegasos Algorithm\n",
        "[Pegasos: Primal Estimated sub-GrAdient\n",
        "SOlver for SVM](https://prod-edxapp.edx-cdn.org/assets/courseware/v1/16f13f7ac37ae86ebe0372f2410bcec4/asset-v1:MITx+6.86x+1T2019+type@asset+block/resources_pegasos.pdf)  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCTLvW4ycVIO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pegasos_single_step_update(\n",
        "        feature_vector,\n",
        "        label,\n",
        "        L,\n",
        "        eta,\n",
        "        current_theta,\n",
        "        current_theta_0):\n",
        "    \"\"\"\n",
        "    Properly updates the classification parameter, theta and theta_0, on a\n",
        "    single step of the Pegasos algorithm\n",
        "\n",
        "    Args:\n",
        "        feature_vector - A numpy array describing a single data point.\n",
        "        label - The correct classification of the feature vector.\n",
        "        L - The lamba value being used to update the parameters.\n",
        "        eta - Learning rate to update parameters.\n",
        "        current_theta - The current theta being used by the Pegasos\n",
        "            algorithm before this update.\n",
        "        current_theta_0 - The current theta_0 being used by the\n",
        "            Pegasos algorithm before this update.\n",
        "\n",
        "    Returns: A tuple where the first element is a numpy array with the value of\n",
        "    theta after the current update has completed and the second element is a\n",
        "    real valued number with the value of theta_0 after the current updated has\n",
        "    completed.\n",
        "    \"\"\"\n",
        "    # Your code here\n",
        "    theta = np.concatenate((float(current_theta_0), current_theta), axis=None) # add preceding theta_0\n",
        "    x = np.concatenate(([1], feature_vector), axis=None) # add preceding 1\n",
        "    if label * theta.dot(x) <= 1:\n",
        "      theta[1:] *= (1-eta*L) # penalize theta\n",
        "      theta += eta*label*x # update theta\n",
        "    else:\n",
        "      theta[1:] *= (1-eta*L) # penalize theta\n",
        "      \n",
        "    return theta[1:], theta[0]\n",
        "\n",
        "def test_pegasos_single_step_update(feature_vector, label, L, eta, current_theta, current_theta_0, exp_theta, exp_theta_0):\n",
        "  theta, theta_0 = pegasos_single_step_update(feature_vector, label, L, eta, current_theta, current_theta_0)\n",
        "  npt.assert_equal(theta, exp_theta)\n",
        "  npt.assert_allclose(theta_0, exp_theta_0)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  feature_vector = np.array([1, 2])\n",
        "  label, theta, theta_0 = 1, np.array([-1, 1]), -1.5\n",
        "  L = 0.2\n",
        "  eta = 0.1\n",
        "  exp_theta, exp_theta_0 = (np.array([-0.88, 1.18]), -1.4)\n",
        "  test_pegasos_single_step_update(feature_vector, label, L, eta, theta, theta_0, exp_theta, exp_theta_0)\n",
        "\n",
        "  feature_vector = np.array([1, 1])\n",
        "  label, theta, theta_0 = 1, np.array([-1, 1]), 1\n",
        "  L = 0.2\n",
        "  eta = 0.1\n",
        "  exp_theta, exp_theta_0 = (np.array([-0.88, 1.08]), 1.1)\n",
        "  test_pegasos_single_step_update(feature_vector, label, L, eta, theta, theta_0, exp_theta, exp_theta_0)\n",
        "\n",
        "  feature_vector = np.array([1, 2])\n",
        "  label, theta, theta_0 = 1, np.array([-1, 1]), -2\n",
        "  L = 0.2\n",
        "  eta = 0.1\n",
        "  exp_theta, exp_theta_0 = (np.array([-0.88, 1.18]), -1.9)\n",
        "  test_pegasos_single_step_update(feature_vector, label, L, eta, theta, theta_0, exp_theta, exp_theta_0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajQZjSUVOtHl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pegasos(feature_matrix, labels, T, L):\n",
        "    \"\"\"\n",
        "    Runs the Pegasos algorithm on a given set of data. Runs T\n",
        "    iterations through the data set, there is no need to worry about\n",
        "    stopping early.\n",
        "\n",
        "    For each update, set learning rate = 1/sqrt(t),\n",
        "    where t is a counter for the number of updates performed so far (between 1\n",
        "    and nT inclusive).\n",
        "\n",
        "    NOTE: Please use the previously implemented functions when applicable.\n",
        "    Do not copy paste code from previous parts.\n",
        "\n",
        "    Args:\n",
        "        feature_matrix - A numpy matrix describing the given data. Each row\n",
        "            represents a single data point.\n",
        "        labels - A numpy array where the kth element of the array is the\n",
        "            correct classification of the kth row of the feature matrix.\n",
        "        T - An integer indicating how many times the algorithm\n",
        "            should iterate through the feature matrix.\n",
        "        L - The lamba value being used to update the Pegasos\n",
        "            algorithm parameters.\n",
        "\n",
        "    Returns: A tuple where the first element is a numpy array with the value of\n",
        "    the theta, the linear classification parameter, found after T\n",
        "    iterations through the feature matrix and the second element is a real\n",
        "    number with the value of the theta_0, the offset classification\n",
        "    parameter, found after T iterations through the feature matrix.\n",
        "    \"\"\"\n",
        "    # Your code here\n",
        "    n, d = feature_matrix.shape\n",
        "    x = np.column_stack((np.ones(n), feature_matrix)) # add preceding 1's\n",
        "    theta = np.zeros(d + 1) # theta_0 and theta combined\n",
        "    counter = 1\n",
        "    for t in range(T):\n",
        "        for i in get_order(feature_matrix.shape[0]):\n",
        "            # Your code here\n",
        "            eta = 1/np.sqrt(counter)\n",
        "            if labels[i] * theta.dot(x[i]) <= 1:\n",
        "              theta[1:] *= (1-eta*L) # penalize theta\n",
        "              theta += eta * labels[i] * x[i] # update theta\n",
        "            else:\n",
        "              theta[1:] *= (1-eta*L) # penalize theta\n",
        "\n",
        "            counter += 1\n",
        "              \n",
        "    return theta[1:], theta[0]\n",
        "\n",
        "def test_pegasos(feature_matrix, labels, T, L, exp_theta, exp_theta_0):\n",
        "  theta, theta_0 = pegasos(feature_matrix, labels, T, L)\n",
        "  npt.assert_equal(theta, exp_theta)\n",
        "  npt.assert_equal(theta_0, exp_theta_0)\n",
        "  \n",
        "if __name__ == \"__main__\":\n",
        "  feature_matrix = np.array([[1, 2]])\n",
        "  labels = np.array([1])\n",
        "  T = 1\n",
        "  L = 0.2\n",
        "  exp_theta, exp_theta_0 = (np.array([1, 2]), 1)\n",
        "  test_pegasos(feature_matrix, labels, T, L, exp_theta, exp_theta_0)\n",
        "\n",
        "  feature_matrix = np.array([[1, 1], [1, 1]])\n",
        "  labels = np.array([1, 1])\n",
        "  T = 1\n",
        "  L = 1\n",
        "  exp_theta, exp_theta_0 = (np.array([1-1/np.sqrt(2), 1-1/np.sqrt(2)]), 1)\n",
        "  test_pegasos(feature_matrix, labels, T, L, exp_theta, exp_theta_0)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}